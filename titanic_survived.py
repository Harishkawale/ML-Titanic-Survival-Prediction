# -*- coding: utf-8 -*-
"""Titanic_Survived.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZckMeRm1WGFthQ3DeCfuY-teWXYcuIC5

Import Libraries
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

"""Load the data"""

titanic= sns.load_dataset('titanic')

"""Print first 10 rows of the data"""

titanic.head(10)

"""Count the number of row and columns in the dataset"""

titanic.shape

"""Get some Statistics"""

titanic.describe()

"""Count the number of survivors"""

titanic['survived'].value_counts()

"""Visualize the count survivors"""

sns.countplot(titanic['survived'])

"""Visualize the count survivors for columns 'who' , 'sex', 'pclass', 'sibsp', 'parch', 'embarked'."""

cols=['who' , 'sex', 'pclass', 'sibsp', 'parch', 'embarked']
n_rows=2
n_cols=3

#The subplot grid and fig size of each graph

fig,axs=plt.subplots(n_rows,n_cols,figsize=(n_cols*3.2,n_rows*3.2))

for r in range(0,n_rows):
  for c in range(0,n_cols):

    i=r*n_cols+ c #index to go through the no. of columns
    ax = axs[r][c] #show where to position each sub plot
    sns.countplot(titanic[cols[i]], hue=titanic['survived'], ax=ax)
    ax.set_title(cols[i])
    ax.legend(title='survived', loc='upper right')

plt.tight_layout()

"""Look at servival rate by sex"""

titanic.groupby('sex')[['survived']].mean()

"""look at survival rate by sex and class"""

titanic.pivot_table('survived', index='sex',columns='class')

"""look at survival rate by sex and class visually"""

titanic.pivot_table('survived', index='sex',columns='class').plot()

"""Plot survival rate of each class"""

sns.barplot(x='class', y='survived', data= titanic)

"""Look the survival rate by sex, age and class"""

age=pd.cut(titanic['age'],[0,18,80])
titanic.pivot_table('survived',['sex',age],'class')

"""Plot the prices paid of each class"""

plt.scatter(titanic['fare'], titanic['class'], color ='purple', label= 'Passenger Paid')
plt.ylabel('Class')
plt.xlabel('Price/Fare')
plt.title('Price of each Class')
plt.legend()
plt.show()

"""Count the empty values in each column"""

titanic.isna().sum()

"""Look at all of the values in each column and get a count """

for val in titanic:
  print(titanic[val].value_counts())
  print( )

"""Drope the columns"""

titanic=titanic.drop(['deck', 'embark_town','alive','class','who','alone','adult_male'],axis=1)

"""Remove the rows with missing values"""

titanic=titanic.dropna(subset=['embarked','age'])

"""Count the new number of rows and columns in the data set"""

titanic.shape

"""Look the data type"""

titanic.dtypes

"""Print the unique values in the columns"""

print(titanic['sex'].unique())
print(titanic['embarked'].unique())

from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()

"""Encode the sex and embaraked columns"""

titanic.iloc[:,2]=labelencoder.fit_transform(titanic.iloc[:,2].values)
#Encode the embarked
titanic.iloc[:,7]=labelencoder.fit_transform(titanic.iloc[:,7].values)

"""Print the NEW unique values in the columns"""

print(titanic['sex'].unique())
print(titanic['embarked'].unique())

"""Look the data type"""

titanic.dtypes

"""Split the data into independent 'X' and dependent 'Y' variables"""

X = titanic.iloc[:, 1:8].values 
Y = titanic.iloc[:, 0].values

"""Split the dataset into 80% Training set and 20% Testing set"""

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)

"""Scale the data"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""Create a function within many Machine Learning Models"""

def models(X_train,Y_train):
  
  #Using Logistic Regression
  from sklearn.linear_model import LogisticRegression
  log = LogisticRegression(random_state = 0)
  log.fit(X_train, Y_train)
  
  #Using KNeighborsClassifier 
  from sklearn.neighbors import KNeighborsClassifier
  knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
  knn.fit(X_train, Y_train)

  #Using SVC (iinear kernel)
  from sklearn.svm import SVC
  svc_lin = SVC(kernel = 'linear', random_state = 0)
  svc_lin.fit(X_train, Y_train)

  #Using SVC method(RBF kernel)
  from sklearn.svm import SVC
  svc_rbf = SVC(kernel = 'rbf', random_state = 0)
  svc_rbf.fit(X_train, Y_train)

  #Using GaussianNB method
  from sklearn.naive_bayes import GaussianNB
  gauss = GaussianNB()
  gauss.fit(X_train, Y_train)

  #Using DecisionTreeClassifier
  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
  tree.fit(X_train, Y_train)

  #Using RandomForestClassifier method
  from sklearn.ensemble import RandomForestClassifier
  forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
  forest.fit(X_train, Y_train)
  
  #print model accuracy on the training data.
  print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train))
  print('[1]K Nearest Neighbor Training Accuracy:', knn.score(X_train, Y_train))
  print('[2]Support Vector Machine (Linear Classifier) Training Accuracy:', svc_lin.score(X_train, Y_train))
  print('[3]Support Vector Machine (RBF Classifier) Training Accuracy:', svc_rbf.score(X_train, Y_train))
  print('[4]Gaussian Naive Bayes Training Accuracy:', gauss.score(X_train, Y_train))
  print('[5]Decision Tree Classifier Training Accuracy:', tree.score(X_train, Y_train))
  print('[6]Random Forest Classifier Training Accuracy:', forest.score(X_train, Y_train))
  
  return log, knn, svc_lin, svc_rbf, gauss, tree, forest

"""Get and train all of the models"""

model = models(X_train,Y_train)

"""Show the confusion matrix and accuracy for all of the hte model on the test data"""

from sklearn.metrics import confusion_matrix 
for i in range(len(model)):
   cm = confusion_matrix(Y_test, model[i].predict(X_test)) 
#Extracting TN, FP, FN, TP
   TN, FP, FN, TP = confusion_matrix(Y_test, model[i].predict(X_test)).ravel()
   test_score = (TP + TN) / (TP + TN + FN + FP)
   print(cm)
   print('Model[{}] Testing Accuracy = "{} !"'.format(i, test_score))
   print( )

"""Get the importance of the features"""

forest = model[6]
importances = pd.DataFrame({'feature':titanic.iloc[:, 1:8].columns,'importance':np.round(forest.feature_importances_,3)})
importances = importances.sort_values('importance',ascending=False).set_index('feature')
importances

"""Visualize the importance"""

importances.plot.bar()

"""Print the prediction of the random forest classifier"""

pred = model[6].predict(X_test)
print(pred)

"""Print the actual values"""

print(Y_test)

"""My survival"""

my_survival=[[1,0,29,3,3,300,1]]

"""Scaling my survival"""

from sklearn.preprocessing import StandardScaler
sc= StandardScaler()
my_survival_scaled = sc.fit_transform(my_survival)

"""Print prediction of my survival using Random forest classifier"""

pred = model[6].predict(my_survival_scaled)
print(pred)
if pred ==0:
  print('oh no! Yoy did not make it')
else:
  print('Nice! You survived ')

a=10
for num in range(2,a+1):
  for i in range(2,num):
    if num%i==0:
      break
  
  else:
    print(num)